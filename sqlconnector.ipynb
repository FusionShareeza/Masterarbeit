{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/Keras: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "#data preprocessing\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "#ml stuff\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "print('Tensorflow/Keras: %s' % keras.__version__)\n",
    "from keras.models import Sequential \n",
    "from keras import Input \n",
    "from keras.layers import Dense\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#utils/visualization\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dill as pickle\n",
    "from ydata_profiling import ProfileReport\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import functools\n",
    "import operator \n",
    "from more_itertools import flatten\n",
    "from collections import Counter\n",
    "#config vars\n",
    "pd.options.display.max_columns=1000\n",
    "pd.options.display.max_rows = 10000\n",
    "pd.options.display.max_seq_items = 100\n",
    "verbose=1\n",
    "\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import sqlalchemy as sa\n",
    "import urllib\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Database and get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD and slower\n",
    "def connect_to_db(connection_string,\n",
    "                    database,\n",
    "                    driver = 'SQL Server Native Client 11.0',\n",
    "                    user = 'CCAdmin',\n",
    "                    password = 'Miw6RjnTGmPHLYF9mG1o'\n",
    "):\n",
    "    connection = pyodbc.connect(\"Driver={\"+driver+\"};\"\n",
    "                        \"Server=\"+connection_string+\";\"\n",
    "                        \"Database=\"+database+\";\"\n",
    "                        \"uid=\"+user+\";pwd=\"+password+\"\")\n",
    "    return connection\n",
    "\n",
    "def get_table_data(table_name, connection):\n",
    "    query = \"SELECT * FROM {}\".format(table_name)\n",
    "    df = pd.read_sql_query(query, connection)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_table_cclogattributes = get_table_data('CCLogAttributes', connect_to_db(connection_string= 'classconprocessingger.database.windows.net', database = 'T_'+tenant+''))\n",
    "df_table_cclogattributes = df_table_cclogattributes.drop(['Zone','Attribute_DataType','LogTimeTicks'], axis=1)\n",
    "\n",
    "df_table_cclogattributes = df_table_cclogattributes.replace('\\n',' ', regex=True)\n",
    "df_table_cclogattributes = df_table_cclogattributes.replace('\\r',' ', regex=True)\n",
    "df_table_cclogattributes.to_csv('data/cclogattributes_T_'+tenant+'.csv', index=False, header= True, encoding='utf-8')#iso-8859-15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenant = '0001ai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db_better(connection_string,\n",
    "                    database,\n",
    "                    driver = 'SQL Server Native Client 11.0',\n",
    "                    user = 'CCAdmin',\n",
    "                    password = 'Miw6RjnTGmPHLYF9mG1o'\n",
    "):\n",
    "    odbc_str = 'DRIVER='+driver+';SERVER='+connection_string+';PORT=1433;UID='+user+';DATABASE='+ database + ';PWD='+ password\n",
    "    connect_str = 'mssql+pyodbc:///?odbc_connect=' + urllib.parse.quote_plus(odbc_str)\n",
    "\n",
    "    return connect_str\n",
    "\n",
    "\n",
    "def get_table_data_CCLOG(table_name, connect_str, startdate, enddate):\n",
    "    engine = create_engine(connect_str)\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(text(\"SELECT * FROM [dbo].[\"+table_name+\"] where LogTime >= \"+startdate+\" and LogTime <= \"+enddate+''\"\"), conn)\n",
    "        return df\n",
    "\n",
    "def get_table_data_ALL(table_name, connect_str):\n",
    "    engine = create_engine(connect_str)\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(text(\"SELECT * FROM [dbo].[\"+table_name+\"]\"), conn)\n",
    "        return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "#ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "asdf"
    ]
   },
   "outputs": [],
   "source": [
    "dist = df['Delta'].value_counts()\n",
    "trace = go.Pie(values=(np.array(dist)),labels=dist.index,  pull=[0, 0])\n",
    "layout = go.Layout(title='Delta Distribution')\n",
    "data = [trace]\n",
    "fig = go.Figure(trace,layout)\n",
    "fig.update_traces(marker=dict(line=dict(color='#000000', width=0.5)), textinfo='value+percent', insidetextorientation='auto')\n",
    "#sfig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = df['Type'].value_counts()\n",
    "trace = go.Pie(values=(np.array(dist)),labels=dist.index,  pull=[0, 0.4,0.2,0.1])\n",
    "layout = go.Layout(title='Type Distribution')\n",
    "data = [trace]\n",
    "fig = go.Figure(trace,layout)\n",
    "fig.update_traces(marker=dict(line=dict(color='#000000', width=0.5)), textinfo='value+percent', insidetextorientation='auto')\n",
    "#sfig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sollerkennungswerte bestimmen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sollwerte(key, df):\n",
    "    df_ordernum = df.loc[(df['Attribute_Name'] == 'OrderNum')] #&(df['Delta'] == False)\n",
    "    dist = df_ordernum['Delta'].value_counts(normalize=True)\n",
    "    print('Kreditor: '+key+'')\n",
    "    \n",
    "    try:\n",
    "        score = 1 - dist.loc[True]\n",
    "    except:\n",
    "        score = dist.loc[False]\n",
    "\n",
    "    print('q(OrderNum): '+str(score)+'') \n",
    "\n",
    "\n",
    "    df_ordernum_correct = df.loc[(df['Attribute_Name'] == 'OrderNum') &(df['Delta'] == False)] \n",
    "    documentid_list = df_ordernum_correct[['DocumentID']].values.tolist()\n",
    "    merged = list(itertools.chain.from_iterable(documentid_list))\n",
    "    denonimator_ordernum = len(documentid_list)\n",
    "    \n",
    "\n",
    "    df_debitor_ordernum = df.loc[(df['Attribute_Name'] == 'OrderNum')|(df['Attribute_Name'] == 'DEBITOR_NUM')|(df['Attribute_Name'] == 'VENDOR_NUM')]\n",
    "    #print(df_debitor_ordernum)\n",
    "    #df_debitor_ordernum.to_csv('data/debitor_preprocessing.csv', index=False, header= True, encoding='iso-8859-15')\n",
    "    \n",
    "\n",
    "\n",
    "    counter_do=0\n",
    "    counter_vo=0\n",
    "    for entry_1 in merged:\n",
    "        speicher_entry_new = df_debitor_ordernum[df_debitor_ordernum.DocumentID == ''.join(str(entry_1))]\n",
    "        if ((speicher_entry_new.Attribute_Name == 'OrderNum') & (speicher_entry_new.Delta == False)).any(): \n",
    "            if ((speicher_entry_new.Attribute_Name == 'DEBITOR_NUM')&(speicher_entry_new.Delta == False)).any():\n",
    "                    counter_do += 1\n",
    "            if ((speicher_entry_new.Attribute_Name == 'VENDOR_NUM')&(speicher_entry_new.Delta == False)).any():\n",
    "                    counter_vo += 1\n",
    "    try:\n",
    "        print('q(Mandant|OrderNum): '+str(counter_do/denonimator_ordernum)+'')\n",
    "        print('q(Vendor|OrderNum): '+str(counter_vo/denonimator_ordernum)+'')\n",
    "    except:\n",
    "         print('error')\n",
    "\n",
    "    counter_vno=0\n",
    "\n",
    "    df_order_delta = df.loc[(df['Attribute_Name'] == 'OrderNum')&(df['Delta'] == True)]\n",
    "    df_order_delta_documentid = df_order_delta[['DocumentID']]\n",
    "    order_delta_list = df_order_delta_documentid.values.tolist()\n",
    "    order_delta_list_merged = list(itertools.chain.from_iterable(order_delta_list))\n",
    "    denominator_order_delta_num = len(order_delta_list_merged)\n",
    "\n",
    "\n",
    "    df_invoicenumber_order_delta = df.loc[(df['Attribute_Name'] == 'DEBITOR_NUM')|(df['Attribute_Name'] == 'OrderNum')]\n",
    "    for entry_order_delta_invoicenumber in order_delta_list_merged:\n",
    "        speicher_entry_order_delta = df_invoicenumber_order_delta[df_invoicenumber_order_delta.DocumentID == ''.join(str(entry_order_delta_invoicenumber))]\n",
    "        if ((speicher_entry_order_delta.Attribute_Name == 'OrderNum') & (speicher_entry_order_delta.Delta == True)).any(): \n",
    "            if ((speicher_entry_order_delta.Attribute_Name == 'DEBITOR_NUM') & (speicher_entry_order_delta.Delta == False)).any():\n",
    "                    counter_vno += 1\n",
    "\n",
    "    if(counter_vno == 0):\n",
    "        print('Da keine falsche Ordernum existiert ist Mandant|!Ordernum 0')\n",
    "    else:\n",
    "        print('q(Mandant|!OrderNum): '+str(counter_vno/denominator_order_delta_num)+'')\n",
    "        \n",
    "    df_vendor_nodelta = df.loc[(df['Attribute_Name'] == 'VENDOR_NUM')&(df['Delta'] == False)]\n",
    "    df_vendor_documentid = df_vendor_nodelta[['DocumentID']]\n",
    "    vendor_list = df_vendor_documentid.values.tolist()\n",
    "    vendor_list_merged = list(itertools.chain.from_iterable(vendor_list))\n",
    "    denominator_vendor_num = len(vendor_list)\n",
    "\n",
    "    df_invoicenumber_vendor = df.loc[(df['Attribute_Name'] == 'InvoiceNumber')|(df['Attribute_Name'] == 'VENDOR_NUM')|(df['Attribute_Name'] == 'InvoiceDate')|(df['Attribute_Name'] == 'InvoiceDate')|(df['Attribute_Name'] == 'GrossAmount')]\n",
    "\n",
    "    counter_inv=0\n",
    "    counter_idv=0\n",
    "    counter_gv=0\n",
    "\n",
    "    for entry_vendor_invoicenumber in vendor_list_merged:\n",
    "        speicher_entry_vendor = df_invoicenumber_vendor[df_invoicenumber_vendor.DocumentID == ''.join(str(entry_vendor_invoicenumber))]\n",
    "        if ((speicher_entry_vendor.Attribute_Name == 'VENDOR_NUM') & (speicher_entry_vendor.Delta == False)).any(): \n",
    "            if ((speicher_entry_vendor.Attribute_Name == 'InvoiceNumber') & (speicher_entry_vendor.Delta == False)).any():\n",
    "                    counter_inv += 1\n",
    "            if ((speicher_entry_vendor.Attribute_Name == 'InvoiceDate') & (speicher_entry_vendor.Delta == False)).any():\n",
    "                    counter_idv += 1\n",
    "            if ((speicher_entry_vendor.Attribute_Name == 'GrossAmount') & (speicher_entry_vendor.Delta == False)).any():\n",
    "                    counter_gv += 1\n",
    "\n",
    "    try:\n",
    "        print('q(InvoiceNumber|Vendor): '+str(counter_inv/denominator_vendor_num)+'')\n",
    "        print('q(InvoiceDate|Vendor): '+str(counter_idv/denominator_vendor_num)+'')\n",
    "        print('q(Gross|Vendor): '+str(counter_gv/denominator_vendor_num)+'')\n",
    "    except:\n",
    "        print('error')\n",
    "    counter_gnv=0\n",
    "\n",
    "    df_vendor_delta = df.loc[(df['Attribute_Name'] == 'VENDOR_NUM')&(df['Delta'] == True)]\n",
    "    df_vendor_delta_documentid = df_vendor_delta[['DocumentID']]\n",
    "    vendor_delta_list = df_vendor_delta_documentid.values.tolist()\n",
    "    vendor_delta_list_merged = list(itertools.chain.from_iterable(vendor_delta_list))\n",
    "    denominator_vendor_delta_num = len(vendor_delta_list_merged)\n",
    "\n",
    "\n",
    "    df_invoicenumber_vendor_delta = df.loc[(df['Attribute_Name'] == 'GrossAmount')|(df['Attribute_Name'] == 'VENDOR_NUM')]\n",
    "    for entry_vendor_delta_invoicenumber in vendor_delta_list_merged:\n",
    "        speicher_entry_vendor_delta = df_invoicenumber_vendor_delta[df_invoicenumber_vendor_delta.DocumentID == ''.join(str(entry_vendor_delta_invoicenumber))]\n",
    "        if ((speicher_entry_vendor_delta.Attribute_Name == 'VENDOR_NUM') & (speicher_entry_vendor_delta.Delta == True)).any(): \n",
    "            if ((speicher_entry_vendor_delta.Attribute_Name == 'GrossAmount') & (speicher_entry_vendor_delta.Delta == False)).any():\n",
    "                    counter_gnv += 1\n",
    "\n",
    "    try:\n",
    "        print('q(Gross|!Vendor): '+str(counter_gnv/denominator_vendor_delta_num)+'')\n",
    "    except:\n",
    "        print('errror')\n",
    "\n",
    "    counter_vom=0\n",
    "\n",
    "    df_order_mandant_delta = df.loc[(df['Attribute_Name'] == 'OrderNum')&(df['Delta'] == True)]\n",
    "    df_order_delta_new = df_order_mandant_delta.loc[(df_order_mandant_delta['Attribute_Name'] == 'Mandant')&(df['Delta'] == False)]\n",
    "    df_order_delta_mandant_documentid = df_order_delta_new[['DocumentID']]\n",
    "    order_delta_mandant_list = df_order_delta_mandant_documentid.values.tolist()\n",
    "    order_delta_mandant_list_merged = list(itertools.chain.from_iterable(order_delta_mandant_list))\n",
    "    denominator_order_delta_mandant_num = len(order_delta_mandant_list_merged)\n",
    "\n",
    "\n",
    "    df_invoicenumber_order_delta_mandant = df.loc[(df['Attribute_Name'] == 'VENDOR_NUM')|(df['Attribute_Name'] == 'OrderNum')|(df['Attribute_Name'] == 'DEBITOR_NUM')]\n",
    "    for entry_order_delta_mandant in order_delta_mandant_list_merged:\n",
    "        speicher_entry_order_delta_mandant = df_invoicenumber_order_delta_mandant[df_invoicenumber_order_delta_mandant.DocumentID == ''.join(str(entry_order_delta_mandant))]\n",
    "        if (((speicher_entry_order_delta_mandant.Attribute_Name == 'OrderNum') & (speicher_entry_order_delta_mandant.Delta == True))&((speicher_entry_order_delta_mandant.Attribute_Name == 'DEBITOR_NUM') & (speicher_entry_order_delta_mandant.Delta == False))).any(): \n",
    "            if ((speicher_entry_order_delta_mandant.Attribute_Name == 'VENDOR_NUM') & (speicher_entry_order_delta_mandant.Delta == False)).any():\n",
    "                    counter_vom += 1\n",
    "\n",
    "    if((counter_vom == 0) | (denominator_order_delta_mandant_num == 0 & counter_vom == 0)):\n",
    "        print('Nulldivision q(Vendor| !OrderNum & Mandant) ungültig')\n",
    "    else:\n",
    "        print('q(Vendor| !OrderNum & Mandant): '+str(counter_vom/denominator_order_delta_mandant_num)+'')\n",
    "\n",
    "\n",
    "    counter_vnom=0\n",
    "\n",
    "    df_order_mandant_delta = df.loc[(df['Attribute_Name'] == 'OrderNum')&(df['Delta'] == True)]\n",
    "    df_order_delta_new = df_order_mandant_delta.loc[(df_order_mandant_delta['Attribute_Name'] == 'Mandant')&(df['Delta'] == True)]\n",
    "    df_order_delta_mandant_documentid = df_order_delta_new[['DocumentID']]\n",
    "    order_delta_mandant_list = df_order_delta_mandant_documentid.values.tolist()\n",
    "    order_delta_mandant_list_merged = list(itertools.chain.from_iterable(order_delta_mandant_list))\n",
    "    denominator_order_ndelta_mandant_num = len(order_delta_mandant_list_merged)\n",
    "\n",
    "\n",
    "    df_invoicenumber_order_delta_mandant = df.loc[(df['Attribute_Name'] == 'VENDOR_NUM')|(df['Attribute_Name'] == 'OrderNum')|(df['Attribute_Name'] == 'DEBITOR_NUM')]\n",
    "    for entry_order_delta_mandant in order_delta_mandant_list_merged:\n",
    "        speicher_entry_order_delta_mandant = df_invoicenumber_order_delta_mandant[df_invoicenumber_order_delta_mandant.DocumentID == ''.join(str(entry_order_delta_mandant))]\n",
    "        if (((speicher_entry_order_delta_mandant.Attribute_Name == 'OrderNum') & (speicher_entry_order_delta_mandant.Delta == True))&((speicher_entry_order_delta_mandant.Attribute_Name == 'DEBITOR_NUM') & (speicher_entry_order_delta_mandant.Delta == True))).any(): \n",
    "            if ((speicher_entry_order_delta_mandant.Attribute_Name == 'VENDOR_NUM') & (speicher_entry_order_delta_mandant.Delta == False)).any():\n",
    "                    counter_vnom += 1\n",
    "\n",
    "    if((counter_vnom == 0) | (denominator_order_ndelta_mandant_num == 0)):\n",
    "        print('Nulldivision q(Vendor| !OrderNum & !Mandant) ungültig')\n",
    "    else:\n",
    "        print('q(Vendor| !OrderNum & !Mandant): '+str(counter_vnom/denominator_order_ndelta_mandant_num)+'')\n",
    "    \n",
    "    print('--------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nach Kreditoren sortieren\n",
    "#Nach Zeit sortieren \n",
    "def split_datframe_into_whatever(splitkey, df_new):\n",
    "    df_split = df_new.loc[(df_new['Attribute_Name'] == splitkey)] \n",
    "\n",
    "    def split_dataframe(df_debitornum, column):\n",
    "        split_dfs = {}\n",
    "        for value in df_debitornum[column].unique():\n",
    "            split_dfs[value] = df_debitornum[df_debitornum[column] == value][['DocumentID']]   \n",
    "        return split_dfs\n",
    "\n",
    "    dc_split_attribute_after = split_dataframe(df_split, 'Attribute_After')\n",
    "\n",
    "\n",
    "    def find_corresponding_values(dict_of_dataframes, column_to_match, large_dataframe):\n",
    "        result_dict = {}\n",
    "        for key, df in dict_of_dataframes.items():\n",
    "            temp_df = large_dataframe[large_dataframe[column_to_match].isin(df[column_to_match])]\n",
    "            result_dict[key] = temp_df\n",
    "        return result_dict\n",
    "\n",
    "    dc_sorted_df = find_corresponding_values(dc_split_attribute_after, \"DocumentID\", df_new)\n",
    "    return dc_sorted_df\n",
    "    #dc_sorted_df_by_creditor[\"\"].to_csv('data/codia.csv', index=False, header= True, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df_by_time(df, start_date, end_date):\n",
    "    # Filtern des DataFrames nach dem Zeitfenster\n",
    "    filtered_df = df[(df['LogTime'] >= start_date) & (df['LogTime'] <= end_date)]  \n",
    "    df_new = filtered_df.drop(['LogTime'], axis =1)\n",
    "    # Rückgabe des gefilterten DataFrames\n",
    "    df_new.to_csv('data/cclogattributes_T_'+tenant+'_reduced.csv', index=False, header= True, encoding='utf-8')#iso-8859-15\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_values(df, value1, bool1, value2, bool2): \n",
    "    df_ordernum_correct = df.loc[(df['Attribute_Name'] == value1) &(df['Delta'] == bool1)] \n",
    "    documentid_list = df_ordernum_correct[['DocumentID']].values.tolist()\n",
    "    merged = list(itertools.chain.from_iterable(documentid_list))\n",
    "    denonimator_ordernum = len(documentid_list)\n",
    "    \n",
    "    df_debitor_ordernum = df.loc[(df['Attribute_Name'] == value1)|(df['Attribute_Name'] == value2)]\n",
    "\n",
    "    counter_do=0\n",
    "    for entry_1 in merged:\n",
    "        speicher_entry_new = df_debitor_ordernum[df_debitor_ordernum.DocumentID == ''.join(str(entry_1))]\n",
    "        if ((speicher_entry_new.Attribute_Name == value1) & (speicher_entry_new.Delta == bool1)).any(): \n",
    "            if ((speicher_entry_new.Attribute_Name == value2)&(speicher_entry_new.Delta == bool2)).any():\n",
    "                    counter_do += 1\n",
    "                    x = speicher_entry_new[\"DocumentID\"]\n",
    "\n",
    "    try:\n",
    "        return counter_do/denonimator_ordernum , x\n",
    "        #return ([counter_do/denonimator_ordernum,counter_do,denonimator_ordernum])\n",
    "    except:\n",
    "         return pd.NA, pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_values2(df, items): \n",
    "    df_ordernum_correct = df.loc[(df['Attribute_Name'] == items[0]) &(df['Delta'] == items[1])] \n",
    "    documentid_list = df_ordernum_correct[['DocumentID']].values.tolist()\n",
    "    merged = list(itertools.chain.from_iterable(documentid_list))\n",
    "    denonimator_ordernum = len(documentid_list)\n",
    "    \n",
    "    df_debitor_ordernum = df.loc[(df['Attribute_Name'] == items[0])|(df['Attribute_Name'] == items[2])]\n",
    "\n",
    "    counter_do=0\n",
    "    for entry_1 in merged:\n",
    "        speicher_entry_new = df_debitor_ordernum[df_debitor_ordernum.DocumentID == ''.join(str(entry_1))]\n",
    "        if ((speicher_entry_new.Attribute_Name == items[0]) & (speicher_entry_new.Delta == items[1])).any(): \n",
    "            if ((speicher_entry_new.Attribute_Name == items[2])&(speicher_entry_new.Delta == False)).any():\n",
    "                    counter_do += 1\n",
    "\n",
    "    try:\n",
    "        #return counter_do/denonimator_ordernum\n",
    "        return counter_do/denonimator_ordernum,denonimator_ordernum\n",
    "    except:\n",
    "         return pd.NA, pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_values_two_booleans(df, value1, bool1, value2, bool2, value3):    \n",
    "    counter_vom=0\n",
    "\n",
    "    df_order_mandant_delta = df.loc[(df['Attribute_Name'] == value1)&(df['Delta'] == bool1)]\n",
    "    df_order_delta_new = df_order_mandant_delta.loc[(df_order_mandant_delta['Attribute_Name'] == value2)&(df['Delta'] == bool2)]\n",
    "    df_order_delta_mandant_documentid = df_order_delta_new[['DocumentID']]\n",
    "    order_delta_mandant_list = df_order_delta_mandant_documentid.values.tolist()\n",
    "    order_delta_mandant_list_merged = list(itertools.chain.from_iterable(order_delta_mandant_list))\n",
    "    denominator_order_delta_mandant_num = len(order_delta_mandant_list_merged)\n",
    "\n",
    "\n",
    "    df_invoicenumber_order_delta_mandant = df.loc[(df['Attribute_Name'] == value1)|(df['Attribute_Name'] == value2)|(df['Attribute_Name'] == value3)]\n",
    "    for entry_order_delta_mandant in order_delta_mandant_list_merged:\n",
    "        speicher_entry_order_delta_mandant = df_invoicenumber_order_delta_mandant[df_invoicenumber_order_delta_mandant.DocumentID == ''.join(str(entry_order_delta_mandant))]\n",
    "        if (((speicher_entry_order_delta_mandant.Attribute_Name == value1) & (speicher_entry_order_delta_mandant.Delta == bool1))&((speicher_entry_order_delta_mandant.Attribute_Name == value2) & (speicher_entry_order_delta_mandant.Delta == bool2))).any(): \n",
    "            if ((speicher_entry_order_delta_mandant.Attribute_Name == value3) & (speicher_entry_order_delta_mandant.Delta == False)).any():\n",
    "                    counter_vom += 1\n",
    "\n",
    "    #if((counter_vom == 0) | (denominator_order_delta_mandant_num == 0 & counter_vom == 0)):\n",
    "    try:\n",
    "        return counter_vom/denominator_order_delta_mandant_num\n",
    "        #return ([counter_vom/denominator_order_delta_mandant_num,counter_vom,denominator_order_delta_mandant_num])\n",
    "    except:\n",
    "         return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_values_two_booleans2(df, items):    \n",
    "    counter_vom=0\n",
    "\n",
    "    df_order_mandant_delta = df.loc[(df['Attribute_Name'] == items[0])&(df['Delta'] == items[1])]\n",
    "    df_order_delta_new = df_order_mandant_delta.loc[(df_order_mandant_delta['Attribute_Name'] == items[2])&(df['Delta'] == items[3])]\n",
    "    df_order_delta_mandant_documentid = df_order_delta_new[['DocumentID']]\n",
    "    order_delta_mandant_list = df_order_delta_mandant_documentid.values.tolist()\n",
    "    order_delta_mandant_list_merged = list(itertools.chain.from_iterable(order_delta_mandant_list))\n",
    "    denominator_order_delta_mandant_num = len(order_delta_mandant_list_merged)\n",
    "\n",
    "\n",
    "    df_invoicenumber_order_delta_mandant = df.loc[(df['Attribute_Name'] == items[0])|(df['Attribute_Name'] == items[2])|(df['Attribute_Name'] == items[4])]\n",
    "    for entry_order_delta_mandant in order_delta_mandant_list_merged:\n",
    "        speicher_entry_order_delta_mandant = df_invoicenumber_order_delta_mandant[df_invoicenumber_order_delta_mandant.DocumentID == ''.join(str(entry_order_delta_mandant))]\n",
    "        if (((speicher_entry_order_delta_mandant.Attribute_Name == items[0]) & (speicher_entry_order_delta_mandant.Delta == items[1]))&((speicher_entry_order_delta_mandant.Attribute_Name == items[2]) & (speicher_entry_order_delta_mandant.Delta == items[3]))).any(): \n",
    "            if ((speicher_entry_order_delta_mandant.Attribute_Name == items[4]) & (speicher_entry_order_delta_mandant.Delta == False)).any():\n",
    "                    counter_vom += 1\n",
    "\n",
    "    #if((counter_vom == 0) | (denominator_order_delta_mandant_num == 0 & counter_vom == 0)):\n",
    "    try:\n",
    "        #return counter_vom/denominator_order_delta_mandant_num\n",
    "        return counter_vom/denominator_order_delta_mandant_num, denominator_order_delta_mandant_num\n",
    "    except:\n",
    "         return pd.NA , pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_value(df, value):\n",
    "    df_ordernum = df.loc[(df['Attribute_Name'] == value)] \n",
    "    dist = df_ordernum['Delta'].value_counts(normalize=True)\n",
    "    try:\n",
    "        score_false = dist.loc[False]\n",
    "        if(score_false >= 0):\n",
    "            score = score_false\n",
    "        elif(score_false == 0):\n",
    "            score = dist.loc[True]\n",
    "    except:\n",
    "        return pd.NA , pd.NA\n",
    "\n",
    "        \n",
    "    return score, len(df_ordernum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [['OrderNum',False,'DEBITOR_NUM'],\n",
    "         ['OrderNum',False,'VENDOR_NUM'],\n",
    "         ['OrderNum',True,'DEBITOR_NUM'],\n",
    "         ['VENDOR_NUM',False,'InvoiceNumber'],\n",
    "         ['VENDOR_NUM',True,'InvoiceNumber'],\n",
    "         ['VENDOR_NUM',False,'InvoiceDate'],\n",
    "         ['VENDOR_NUM',True,'InvoiceDate'],\n",
    "         ['VENDOR_NUM',False,'GrossAmount'],\n",
    "         ['VENDOR_NUM',True,'GrossAmount'],\n",
    "         ['VENDOR_NUM',False,'NetAmount1'],\n",
    "         ['VENDOR_NUM',True,'NetAmount1'],\n",
    "         ['VENDOR_NUM',False,'VatAmount1'],\n",
    "         ['VENDOR_NUM',True,'VatAmount1'],\n",
    "         ]\n",
    "\n",
    "list2 = [['OrderNum',True,'DEBITOR_NUM',False,'VENDOR_NUM'],\n",
    "            ['OrderNum',True,'DEBITOR_NUM',True,'VENDOR_NUM'],\n",
    "            ]\n",
    "\n",
    "def get_data_values_complete_results(tenant, splitkey,df_new):\n",
    "\n",
    "    dc_sorted_df = split_datframe_into_whatever(splitkey, df_new)\n",
    "    \n",
    "    df_results = pd.DataFrame(columns=['q(OrderNum)','q(VENDOR_NUM)',\n",
    "            'q(DEBITOR_NUM|OrderNum)',\n",
    "            'q(VENDOR_NUM|OrderNum)',\n",
    "            'q(DEBITOR_NUM|!OrderNum)',\n",
    "            'q(InvoiceNumber|VENDOR_NUM)',\n",
    "            'q(InvoiceNumber|!VENDOR_NUM)',\n",
    "            'q(InvoiceDate|VENDOR_NUM)',\n",
    "            'q(InvoiceDate|!VENDOR_NUM)',\n",
    "            'q(GrossAmount|VENDOR_NUM)',\n",
    "            'q(GrossAmount|!VENDOR_NUM)',\n",
    "            'q(NetAmount1|VENDOR_NUM)',\n",
    "            'q(NetAmount1|!VENDOR_NUM)',\n",
    "            'q(VatAmount1|VENDOR_NUM)',\n",
    "            'q(VatAmount1|!VENDOR_NUM)',\n",
    "            'q(VENDOR_NUM | !OrderNum & DEBITOR_NUM)',\n",
    "            'q(VENDOR_NUM| !OrderNum & ! DEBITOR_NUM)',\n",
    "            ])\n",
    "    \n",
    "    df_results_frequency= pd.DataFrame(columns=['q(OrderNum)','q(VENDOR_NUM)',\n",
    "            'q(DEBITOR_NUM|OrderNum)',\n",
    "            'q(VENDOR_NUM|OrderNum)',\n",
    "            'q(DEBITOR_NUM|!OrderNum)',\n",
    "            'q(InvoiceNumber|VENDOR_NUM)',\n",
    "            'q(InvoiceNumber|!VENDOR_NUM)',\n",
    "            'q(InvoiceDate|VENDOR_NUM)',\n",
    "            'q(InvoiceDate|!VENDOR_NUM)',\n",
    "            'q(GrossAmount|VENDOR_NUM)',\n",
    "            'q(GrossAmount|!VENDOR_NUM)',\n",
    "            'q(NetAmount1|VENDOR_NUM)',\n",
    "            'q(NetAmount1|!VENDOR_NUM)',\n",
    "            'q(VatAmount1|VENDOR_NUM)',\n",
    "            'q(VatAmount1|!VENDOR_NUM)',\n",
    "            'q(VENDOR_NUM | !OrderNum & DEBITOR_NUM)',\n",
    "            'q(VENDOR_NUM| !OrderNum & ! DEBITOR_NUM)',\n",
    "            ])\n",
    "\n",
    "    for key, df in dc_sorted_df.items():\n",
    "    \n",
    "        result_list = []\n",
    "        result_list_frequency = []\n",
    "        #get_sollwerte(key, df)\n",
    "        ordernum, ordernum_frequency = get_single_value(df, 'OrderNum')\n",
    "        result_list.append(ordernum)\n",
    "        result_list_frequency.append(ordernum_frequency)\n",
    "\n",
    "        #print(''+key+': '+'OrderNum = '+str(ordernum)+'')\n",
    "        #Für Simon ai1\n",
    "        #x, y= get_data_values(df, 'VENDOR_NUM', False, 'InvoiceNumber', True)\n",
    "        #print(key)\n",
    "        #print(x,y)\n",
    "\n",
    "        vendornum, vendornum_frequency = get_single_value(df, 'VENDOR_NUM')\n",
    "        #print(''+key+': '+'VENDOR_NUM = '+str(vendornum)+'')\n",
    "        result_list.append(vendornum)\n",
    "        result_list_frequency.append(vendornum_frequency)\n",
    "\n",
    "        for items1 in list1:\n",
    "            value, value_frequency = get_data_values2(df, items1)\n",
    "            result_list.append(value)\n",
    "            result_list_frequency.append(value_frequency)\n",
    "\n",
    "        for items2 in list2:\n",
    "            twovalues, twovalues_frequency = get_data_values_two_booleans2(df, items2)\n",
    "            result_list.append(twovalues)\n",
    "            result_list_frequency.append(twovalues_frequency)\n",
    "            \n",
    "\n",
    "        df_results.loc[key] = result_list\n",
    "        df_results_frequency.loc[key] = result_list_frequency\n",
    "\n",
    "        \n",
    "    return df_results, df_results_frequency ,dc_sorted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sollwerte bestimmen\n",
    "\n",
    "def sollwerte_anhand_wahrscheinlichkeit(df):\n",
    "    sollwerte = pd.Series()\n",
    "    for column in df.columns:\n",
    "        #df.values.tolist()\n",
    "        probability = []\n",
    "        count = []\n",
    "        for entry in df[column]:\n",
    "            #df.values.tolist()\n",
    "            if (pd.isnull(entry)):\n",
    "                continue      \n",
    "            else:\n",
    "                probability.append(entry[0])\n",
    "                count.append(entry[1])\n",
    "\n",
    "        wholecount = sum(count)\n",
    "        gesamtwahrscheinlichkeit = sum([p * h / wholecount for p, h in zip(probability, count)])  #p = probability * count/wholcount\n",
    "\n",
    "        sollwerte[column] = gesamtwahrscheinlichkeit\n",
    "    return sollwerte\n",
    "\n",
    "sollwerte = sollwerte_anhand_wahrscheinlichkeit(df_results)\n",
    "#sollwerte.to_csv('data/sollwerte.csv', index=True, header= True, encoding='utf-8')\n",
    "print(sollwerte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>q(OrderNum)</th>\n",
       "      <th>q(VENDOR_NUM)</th>\n",
       "      <th>q(DEBITOR_NUM|OrderNum)</th>\n",
       "      <th>q(VENDOR_NUM|OrderNum)</th>\n",
       "      <th>q(DEBITOR_NUM|!OrderNum)</th>\n",
       "      <th>q(InvoiceNumber|VENDOR_NUM)</th>\n",
       "      <th>q(InvoiceNumber|!VENDOR_NUM)</th>\n",
       "      <th>q(InvoiceDate|VENDOR_NUM)</th>\n",
       "      <th>q(InvoiceDate|!VENDOR_NUM)</th>\n",
       "      <th>q(GrossAmount|VENDOR_NUM)</th>\n",
       "      <th>q(GrossAmount|!VENDOR_NUM)</th>\n",
       "      <th>q(NetAmount1|VENDOR_NUM)</th>\n",
       "      <th>q(NetAmount1|!VENDOR_NUM)</th>\n",
       "      <th>q(VatAmount1|VENDOR_NUM)</th>\n",
       "      <th>q(VatAmount1|!VENDOR_NUM)</th>\n",
       "      <th>q(VENDOR_NUM | !OrderNum &amp; DEBITOR_NUM)</th>\n",
       "      <th>q(VENDOR_NUM| !OrderNum &amp; ! DEBITOR_NUM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gewichtung</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0  q(OrderNum)  q(VENDOR_NUM)  q(DEBITOR_NUM|OrderNum)  \\\n",
       "0                   1.0          0.961                      1.0   \n",
       "Gewichtung          1.0          2.000                      2.0   \n",
       "\n",
       "Unnamed: 0  q(VENDOR_NUM|OrderNum)  q(DEBITOR_NUM|!OrderNum)  \\\n",
       "0                            0.797                     0.734   \n",
       "Gewichtung                   1.000                     2.000   \n",
       "\n",
       "Unnamed: 0  q(InvoiceNumber|VENDOR_NUM)  q(InvoiceNumber|!VENDOR_NUM)  \\\n",
       "0                                 0.963                         0.906   \n",
       "Gewichtung                        1.000                         1.000   \n",
       "\n",
       "Unnamed: 0  q(InvoiceDate|VENDOR_NUM)  q(InvoiceDate|!VENDOR_NUM)  \\\n",
       "0                               0.974                        0.85   \n",
       "Gewichtung                      1.000                        0.50   \n",
       "\n",
       "Unnamed: 0  q(GrossAmount|VENDOR_NUM)  q(GrossAmount|!VENDOR_NUM)  \\\n",
       "0                               0.981                         0.8   \n",
       "Gewichtung                      2.000                         1.0   \n",
       "\n",
       "Unnamed: 0  q(NetAmount1|VENDOR_NUM)  q(NetAmount1|!VENDOR_NUM)  \\\n",
       "0                              0.878                        0.8   \n",
       "Gewichtung                     0.700                        0.7   \n",
       "\n",
       "Unnamed: 0  q(VatAmount1|VENDOR_NUM)  q(VatAmount1|!VENDOR_NUM)  \\\n",
       "0                              0.885                        0.8   \n",
       "Gewichtung                     0.700                        0.7   \n",
       "\n",
       "Unnamed: 0  q(VENDOR_NUM | !OrderNum & DEBITOR_NUM)  \\\n",
       "0                                               0.0   \n",
       "Gewichtung                                      1.0   \n",
       "\n",
       "Unnamed: 0  q(VENDOR_NUM| !OrderNum & ! DEBITOR_NUM)  \n",
       "0                                                0.0  \n",
       "Gewichtung                                       1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sollwerte = pd.read_csv('data/sollwerte.csv', encoding='utf-8')\n",
    "sollwerte_transposed = sollwerte.set_index('Unnamed: 0').T\n",
    "display(sollwerte_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_element(row):\n",
    "    return row[0]\n",
    "\n",
    "def get_outliers(df_results):\n",
    "    outliers_dataframe = pd.Series([],dtype=pd.StringDtype())\n",
    "\n",
    "    for col in sollwerte_transposed:\n",
    "        #print(sollwerte_transposed[col])\n",
    "        std = df_results[col].std()\n",
    "        sollwert = sollwerte_transposed.iloc[0][col]\n",
    "        gewichtung = sollwerte_transposed.iloc[1][col]\n",
    "        absoluter_abstand = np.abs(sollwert - df_results[col])\n",
    "        outliers = df_results[(df_results[col] - sollwert).abs() > 0.3] #2 * std ((1-sollwert)/2)\n",
    "        #print(outliers.index.tolist())\n",
    "        if not outliers.empty:\n",
    "            outliers_dataframe[col] = outliers.index.tolist()\n",
    "            #print(f\"Ausreißer in Spalte {col}:\")\n",
    "            #print(outliers.index)\n",
    "            #return(col, outliers.index)\n",
    "\n",
    "    return(outliers_dataframe)\n",
    "\n",
    "#median = df_results.median()\n",
    "\n",
    "def sort_outliers(outliers_results, df_results_frequency):\n",
    "    sorted_outliers_dataframe = pd.Series([],dtype=pd.StringDtype())\n",
    "    for entry in outliers_results.items():\n",
    "        filtered_df2 = df_results_frequency[df_results_frequency.index.isin(entry[1])]\n",
    "        sorted_filtered_df2 = filtered_df2.sort_values(by=entry[0], ascending=False)\n",
    "        sorted_filtered_df2 = sorted_filtered_df2[entry[0]]\n",
    "        sorted_outliers_dataframe[entry[0]]  = sorted_filtered_df2.index.tolist()\n",
    "    #print(df_results_debitor_frequency[entry[0]].sort_values(entry[1]))\n",
    "    return sorted_outliers_dataframe\n",
    "    #entry[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_numbers_by_position(df, sollwerte_transposed ,col_name, threshold):\n",
    "    count_numbers = {}\n",
    "    positions = {}\n",
    "    for i, row in df.iterrows():\n",
    "        gewichtung = sollwerte_transposed.iloc[1][i]\n",
    "        for number in row[col_name]:\n",
    "            if number in count_numbers:\n",
    "                count_numbers[number] += 1 * gewichtung\n",
    "            else:\n",
    "                count_numbers[number] = 1\n",
    "            if number in positions:\n",
    "                positions[number].append(row[col_name].index(number))\n",
    "            else:\n",
    "                positions[number] = [row[col_name].index(number)]\n",
    "    \n",
    "    sorted_counts = sorted(count_numbers.items(), key=lambda x: sum(positions[x[0]]) / len(positions[x[0]]))\n",
    "    sorted_numbers = [x[0] for x in sorted_counts]\n",
    "    \n",
    "    threshold_numbers = [x[0] for x in sorted_counts if x[1] > threshold]\n",
    "    \n",
    "    return sorted_numbers, threshold_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = \"'2022-12-20 09:44:23.030'\"\n",
    "enddate = \"'2023-04-19 12:28:20.000'\"\n",
    "\n",
    "df_table_cclogattributes = get_table_data_CCLOG('CCLogAttributes', connect_to_db_better(connection_string= 'classconprocessingger.database.windows.net', database = 'T_'+tenant+'')\n",
    "                                           ,\"\"+startdate+\"\",\"\"+enddate+\"\")\n",
    "df_table_cclogattributes = df_table_cclogattributes.drop(['Zone','LogTime','Attribute_DataType','LogTimeTicks'], axis=1)\n",
    "df_table_cclogattributes = df_table_cclogattributes.replace('\\n',' ', regex=True)\n",
    "df_table_cclogattributes = df_table_cclogattributes.replace('\\r',' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_card = pd.Series([],dtype=pd.StringDtype())\n",
    "sollwerte = pd.read_csv('data/sollwerte.csv', encoding='utf-8')\n",
    "sollwerte_transposed = sollwerte.set_index('Unnamed: 0').T\n",
    "dc_sorted_df_vendor_complete = dict()\n",
    "\n",
    "\n",
    "df_results_debitor,df_results_frequency ,dc_sorted_df_debitor = get_data_values_complete_results(tenant, 'DEBITOR_NUM', df_table_cclogattributes)\n",
    "outliers_results = get_outliers(df_results_debitor)\n",
    "outliers_results_sorted_debitor = sort_outliers(outliers_results, df_results_frequency)\n",
    "outliers_results_debitor_frame = outliers_results_sorted_debitor.to_frame()\n",
    "sorted_counts, high_frequency_numbers_debitor = sort_numbers_by_position(outliers_results_debitor_frame, sollwerte_transposed,0, threshold=3)\n",
    "\n",
    "bad_vendors = []\n",
    "for entry in high_frequency_numbers_debitor:\n",
    "    dc_sorted_df_vendor_complete[entry] = {}\n",
    "    df_results_vendor, df_results_frequency_vendor, dc_sorted_df_vendor = get_data_values_complete_results(tenant, 'VENDOR_NUM', dc_sorted_df_debitor[entry])\n",
    "    dc_sorted_df_vendor_complete[entry].update(dc_sorted_df_vendor)\n",
    "    outliers_results_vendor = get_outliers(df_results_vendor)\n",
    "    outliers_results_sorted_vendor = sort_outliers(outliers_results_vendor, df_results_frequency_vendor)\n",
    "    outliers_results_vendor_frame = outliers_results_sorted_vendor.to_frame()\n",
    "    sorted_counts_vendor, high_frequency_numbers_vendor = sort_numbers_by_position(outliers_results_vendor_frame, sollwerte_transposed, 0, threshold=3)\n",
    "    bad_vendors.append(high_frequency_numbers_vendor)\n",
    "    score_card[entry]  = high_frequency_numbers_vendor\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q(InvoiceNumber|!VENDOR_NUM)</th>\n",
       "      <td>[53143]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q(GrossAmount|!VENDOR_NUM)</th>\n",
       "      <td>[53143]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q(NetAmount1|VENDOR_NUM)</th>\n",
       "      <td>[50631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q(NetAmount1|!VENDOR_NUM)</th>\n",
       "      <td>[53143]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q(VatAmount1|VENDOR_NUM)</th>\n",
       "      <td>[50631]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q(VatAmount1|!VENDOR_NUM)</th>\n",
       "      <td>[53143]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0\n",
       "q(InvoiceNumber|!VENDOR_NUM)  [53143]\n",
       "q(GrossAmount|!VENDOR_NUM)    [53143]\n",
       "q(NetAmount1|VENDOR_NUM)      [50631]\n",
       "q(NetAmount1|!VENDOR_NUM)     [53143]\n",
       "q(VatAmount1|VENDOR_NUM)      [50631]\n",
       "q(VatAmount1|!VENDOR_NUM)     [53143]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(outliers_results_vendor_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q(OrderNum)</th>\n",
       "      <th>q(VENDOR_NUM)</th>\n",
       "      <th>q(DEBITOR_NUM|OrderNum)</th>\n",
       "      <th>q(VENDOR_NUM|OrderNum)</th>\n",
       "      <th>q(DEBITOR_NUM|!OrderNum)</th>\n",
       "      <th>q(InvoiceNumber|VENDOR_NUM)</th>\n",
       "      <th>q(InvoiceNumber|!VENDOR_NUM)</th>\n",
       "      <th>q(InvoiceDate|VENDOR_NUM)</th>\n",
       "      <th>q(InvoiceDate|!VENDOR_NUM)</th>\n",
       "      <th>q(GrossAmount|VENDOR_NUM)</th>\n",
       "      <th>q(GrossAmount|!VENDOR_NUM)</th>\n",
       "      <th>q(NetAmount1|VENDOR_NUM)</th>\n",
       "      <th>q(NetAmount1|!VENDOR_NUM)</th>\n",
       "      <th>q(VatAmount1|VENDOR_NUM)</th>\n",
       "      <th>q(VatAmount1|!VENDOR_NUM)</th>\n",
       "      <th>q(VENDOR_NUM | !OrderNum &amp; DEBITOR_NUM)</th>\n",
       "      <th>q(VENDOR_NUM| !OrderNum &amp; ! DEBITOR_NUM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53143</th>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50631</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      q(OrderNum) q(VENDOR_NUM) q(DEBITOR_NUM|OrderNum)  \\\n",
       "53143         NaN          <NA>                     NaN   \n",
       "50631         NaN             1                     NaN   \n",
       "\n",
       "      q(VENDOR_NUM|OrderNum) q(DEBITOR_NUM|!OrderNum)  \\\n",
       "53143                    NaN                      NaN   \n",
       "50631                    NaN                      NaN   \n",
       "\n",
       "      q(InvoiceNumber|VENDOR_NUM) q(InvoiceNumber|!VENDOR_NUM)  \\\n",
       "53143                        <NA>                            1   \n",
       "50631                           1                         <NA>   \n",
       "\n",
       "      q(InvoiceDate|VENDOR_NUM) q(InvoiceDate|!VENDOR_NUM)  \\\n",
       "53143                      <NA>                          1   \n",
       "50631                         1                       <NA>   \n",
       "\n",
       "      q(GrossAmount|VENDOR_NUM) q(GrossAmount|!VENDOR_NUM)  \\\n",
       "53143                      <NA>                          1   \n",
       "50631                         1                       <NA>   \n",
       "\n",
       "      q(NetAmount1|VENDOR_NUM) q(NetAmount1|!VENDOR_NUM)  \\\n",
       "53143                     <NA>                         1   \n",
       "50631                        1                      <NA>   \n",
       "\n",
       "      q(VatAmount1|VENDOR_NUM) q(VatAmount1|!VENDOR_NUM)  \\\n",
       "53143                     <NA>                         1   \n",
       "50631                        1                      <NA>   \n",
       "\n",
       "      q(VENDOR_NUM | !OrderNum & DEBITOR_NUM)  \\\n",
       "53143                                     NaN   \n",
       "50631                                     NaN   \n",
       "\n",
       "      q(VENDOR_NUM| !OrderNum & ! DEBITOR_NUM)  \n",
       "53143                                      NaN  \n",
       "50631                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_results_frequency_vendor)\n",
    "#dc_sorted_df_debitor[\"d.velop Kiel\"].to_csv('data/d-velop_kiel.csv', index=False, header= True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-velop                      [52174, 59666, 56402, 50066, 57430, 58136, 585...\n",
      "codia                        [50024, 50406, 56466, 57014, 58570, 52287, 598...\n",
      "d.velop Kiel                 [57793, 51418, 50406, 57341, 57778, 50336, 500...\n",
      "d.velop Sulzbach                                         [52174, 59671, 56651]\n",
      "d.velop campus                                                         [50700]\n",
      "d.velop AT                                        [59370, 52893, 59699, 52889]\n",
      "Classcon Consulting                        [50044, 54335, 57341, 58675, 59678]\n",
      "d.velop campus Verwaltung                                              [53143]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(score_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dc_sorted_df_vendor_complete[\"52174\"].to_csv('data/d-52174.csv', index=False, header= True, encoding='utf-8')\n",
    "dc_sorted_df_vendor_complete[\"d-velop\"][\"52174\"].to_csv('data/d-52174.csv', index=False, header= True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_ccvendors = get_table_data_ALL('CC_VENDORS', connect_to_db_better(connection_string= 'classconprocessingger.database.windows.net', database = 'T_'+tenant+''))\n",
    "df_table_ccvendors_bank = get_table_data_ALL('CC_VENDOR_BANK', connect_to_db_better(connection_string= 'classconprocessingger.database.windows.net', database = 'T_'+tenant+''))\n",
    "\n",
    "df_table_ccvendors = df_table_ccvendors.replace('\\n',' ', regex=True)\n",
    "df_table_ccvendors = df_table_ccvendors.replace('\\r',' ', regex=True)\n",
    "df_table_ccvendors_bank = df_table_ccvendors_bank.replace('\\n',' ', regex=True)\n",
    "df_table_ccvendors_bank = df_table_ccvendors_bank.replace('\\r',' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bei: 08adfa64-4959-427c-b1f9-ee18fd3d0e3c:  3\n",
      "Bei: 3391f1ea-08a6-42e4-bd2a-ac873989aa4c:  3\n",
      "Bei: d45da493-f6f9-4f42-8d99-910ebc1d5075:  3\n",
      "Bei: dda5db75-231b-42c9-af45-63de83b89dc1:  3\n",
      "Bei: 989991de-4422-4a4c-9809-a2662f336c16:  3\n"
     ]
    }
   ],
   "source": [
    "vendor_num = '56466'\n",
    "debitor= 'd-velop'\n",
    "df_sort = dc_sorted_df_vendor_complete[debitor][vendor_num]\n",
    "df_sort.to_csv('data/52174.csv', index=False, header= True, encoding='utf-8')\n",
    "df_sort = df_sort[((df_sort['Attribute_Name'] == 'VatAmount1') & (df_sort['Delta'] == True)) | (df_sort['Attribute_Name'] == 'NetAmount1') & (df_sort['Delta'] == True) | (df_sort['Attribute_Name'] == 'VatRate1') & (df_sort['Delta'] == True)]\n",
    "\n",
    "count_good = df_sort['DocumentID'].nunique()\n",
    "unique_documentid = df_sort['DocumentID'].unique()\n",
    "\n",
    "for entry in unique_documentid:\n",
    "        sorted_by_documentid = df_sort.loc[(df_sort[\"DocumentID\"] == entry)]\n",
    "        len_sorted_by_documentid = len(sorted_by_documentid)\n",
    "        #print(sorted_by_documentid)\n",
    "        sorted_by_documentid = sorted_by_documentid.loc[(sorted_by_documentid[\"Attribute_Name\"] == 'VatAmount1')]\n",
    "        if 0.0 < abs(float(sorted_by_documentid[\"Attribute_After\"]) - float(sorted_by_documentid[\"Attribute_Before\"])) <= 0.05:\n",
    "                print('Bei: '+entry+' Rundungsfehler')\n",
    "\n",
    "        print('Bei: '+entry+':  '+str(len_sorted_by_documentid)+'')\n",
    "\n",
    "# count_bad = 0\n",
    "# for index, row in df_sort.iterrows():\n",
    "#     display(row)\n",
    "#     if 0.0 < abs(float(row[\"Attribute_After\"]) - float(row[\"Attribute_Before\"])) <= 0.05:\n",
    "#             count_bad += 1\n",
    "#     #if abs(float(row[\"Attribute_After\"]) - float(row[\"Attribute_Before\"])) != 0.0 and abs(float(row[\"Attribute_After\"]) - float(row[\"Attribute_Before\"])) < 0.05:\n",
    "#             #count_bad += 1\n",
    "# if (count_bad > 0): \n",
    "#     print(\"Fehler bei \"+vendor_num+\":  \"+str(count_bad)+\" von \"+str(count_good)+\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_eap_error(vendor_num, debitor):  \n",
    "        df_sort = dc_sorted_df_vendor_complete[debitor][vendor_num]\n",
    "        df_sort = df_sort[((df_sort['Attribute_Name'] == 'VatAmount1') & (df_sort['Delta'] == True)) | (df_sort['Attribute_Name'] == 'NetAmount1') & (df_sort['Delta'] == True) | (df_sort['Attribute_Name'] == 'VatRate1') & (df_sort['Delta'] == True)]\n",
    "\n",
    "        if vendor_num == 'd-velop':\n",
    "                count_good = df_sort['DocumentID'].nunique()\n",
    "                count_good += count_good\n",
    "        \n",
    "        unique_documentid = df_sort['DocumentID'].unique()\n",
    "        wrong_documentids = []\n",
    "\n",
    "        for entry in unique_documentid:\n",
    "                sorted_by_documentid = df_sort.loc[(df_sort[\"DocumentID\"] == entry)]\n",
    "                len_sorted_by_documentid = len(sorted_by_documentid)\n",
    "                sorted_by_documentid = sorted_by_documentid.loc[(sorted_by_documentid[\"Attribute_Name\"] == 'VatAmount1')]\n",
    "                if not sorted_by_documentid.empty:\n",
    "                        if 0.0 < abs(float(sorted_by_documentid[\"Attribute_After\"]) - float(sorted_by_documentid[\"Attribute_Before\"])) <= 0.05:\n",
    "                                #print('Bei: '+entry+' Rundungsfehler')\n",
    "                                x=1\n",
    "\n",
    "                if not sorted_by_documentid.empty:\n",
    "                        wrong_documentids.append([entry, len_sorted_by_documentid])\n",
    "\n",
    "        return wrong_documentids\n",
    "                        #print('Bei: '+entry+':  '+str(len_sorted_by_documentid)+'')\n",
    "                #if 0.0 < abs(float(sorted_by_documentid[\"Attribute_After\"]) - float(sorted_by_documentid[\"Attribute_Before\"])) <= 0.05:\n",
    "                        #print('Bei: '+entry+' Rundungsfehler')\n",
    "\n",
    "                \n",
    "    # df_sort = dc_sorted_df_vendor_complete[vendor_num]\n",
    "    # df_sort = df_sort[((df_sort['Attribute_Name'] == 'VatAmount1') & (df_sort['Delta'] == True)) | (df_sort['Attribute_Name'] == 'NetAmount1') & (df_sort['Delta'] == True)| (df_sort['Attribute_Name'] == 'VatRate1') & (df_sort['Delta'] == True)]\n",
    "    # count_good = df_sort['DocumentID'].count()\n",
    "    # count_bad = 0\n",
    "    # for index, row in df_sort.iterrows():\n",
    "    #     if abs(float(row[\"Attribute_After\"]) - float(row[\"Attribute_Before\"])) != 0.0 and abs(float(row[\"Attribute_After\"]) - float(row[\"Attribute_Before\"])) < 0.05:\n",
    "    #             count_bad += 1\n",
    "        \n",
    "    # if (count_bad > 0): \n",
    "    #     print(\"Fehler bei \"+vendor_num+\":  \"+str(count_bad)+\" von \"+str(count_good)+\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-velop                      [52174, 111, [[e32a517a-03a0-47d7-af12-4141b88...\n",
      "codia                        [50024, 111, 50406, 11, [[36dedbf7-5c5c-451c-8...\n",
      "d.velop Kiel                 [57793, 111, [[eca2e798-5448-4be8-802b-15c3cfe...\n",
      "d.velop Sulzbach             [52174, 111, [[22e4904c-b990-4741-ab00-da0aab1...\n",
      "d.velop campus                                                     [50700, 10]\n",
      "d.velop AT                       [59370, 111, 52893, 11, 59699, 11, 52889, 11]\n",
      "Classcon Consulting          [50044, 11, 54335, 111, 57341, 111, 58675, 11,...\n",
      "d.velop campus Verwaltung                                         [53143, 111]\n",
      "dtype: object\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "score_card_missing_vendor_vat_registration_id = pd.Series([],dtype=pd.StringDtype())\n",
    "#score_card_missing_vendor_vat_registration_id = pd.DataFrame()\n",
    "fehlercount = 0\n",
    "\n",
    "\n",
    "for entry in score_card:\n",
    "    wrong_number = []\n",
    "    wrong_documentids = []\n",
    "    for item in entry:\n",
    "        #wrong_documentids.append(check_for_eap_error(item, score_card.index[count]))\n",
    "        wrong_documentids = (check_for_eap_error(item, score_card.index[count]))\n",
    "        entry_wrong_number_vat_registration_id = df_table_ccvendors[(df_table_ccvendors['COMPANY_NUM'] == score_card.index[count]) & (df_table_ccvendors[\"VENDOR_NUM\"] == item)& ~(df_table_ccvendors[\"VENDOR_VAT_REGISTRATION_ID\"] == '')]\n",
    "        entry_wrong_number_registration_id = df_table_ccvendors[(df_table_ccvendors['COMPANY_NUM'] == score_card.index[count]) & (df_table_ccvendors[\"VENDOR_NUM\"] == item)& ~(df_table_ccvendors[\"VENDOR_REGISTRATION_ID\"] == '')] \n",
    "        entry_wrong_number_iban = df_table_ccvendors_bank[(df_table_ccvendors_bank['COMPANY_NUM'] == score_card.index[count]) & (df_table_ccvendors_bank[\"VENDOR_NUM\"] == item)& ~(df_table_ccvendors_bank[\"IBAN\"] == '')]\n",
    "        if entry_wrong_number_vat_registration_id.empty: \n",
    "            if item not in wrong_number:\n",
    "                wrong_number.append(item) \n",
    "            fehlercount += 100\n",
    "        if entry_wrong_number_registration_id.empty: \n",
    "            if item not in wrong_number:\n",
    "                wrong_number.append(item)\n",
    "            fehlercount += 10\n",
    "        if entry_wrong_number_iban.empty: \n",
    "            if item not in wrong_number:\n",
    "                wrong_number.append(item)\n",
    "            fehlercount += 1\n",
    "        \n",
    "        wrong_number.append(fehlercount)\n",
    "        if wrong_documentids:\n",
    "            wrong_number.append(wrong_documentids)\n",
    "\n",
    "        fehlercount = 0\n",
    "    #print(wrong_documentids)\n",
    "\n",
    "    score_card_missing_vendor_vat_registration_id[score_card.index[count]] = wrong_number\n",
    "    count += 1\n",
    "\n",
    "print(score_card_missing_vendor_vat_registration_id)\n",
    "print(score_card_missing_vendor_vat_registration_id.to_json('data/scorecard_verbesserung.json', index=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(count_good)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.000000\n",
       "1         0.999880\n",
       "2         0.999895\n",
       "3         0.999853\n",
       "4         0.999756\n",
       "            ...   \n",
       "174147    0.999872\n",
       "174148    0.999898\n",
       "174149    0.999743\n",
       "174150    0.999912\n",
       "174151    0.999801\n",
       "Length: 174152, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>Attribute_Name</th>\n",
       "      <th>Attribute_Before</th>\n",
       "      <th>Attribute_After</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DocumentID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>-0.006891</td>\n",
       "      <td>-0.007502</td>\n",
       "      <td>-0.009454</td>\n",
       "      <td>-0.009810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute_Name</th>\n",
       "      <td>0.000423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011665</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.013810</td>\n",
       "      <td>0.002291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute_Before</th>\n",
       "      <td>-0.006891</td>\n",
       "      <td>0.011665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002284</td>\n",
       "      <td>-0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute_After</th>\n",
       "      <td>-0.007502</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.002802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delta</th>\n",
       "      <td>-0.009454</td>\n",
       "      <td>0.013810</td>\n",
       "      <td>-0.002284</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>-0.009810</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>-0.002284</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.948129</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DocumentID  Attribute_Name  Attribute_Before  \\\n",
       "DocumentID          1.000000        0.000423         -0.006891   \n",
       "Attribute_Name      0.000423        1.000000          0.011665   \n",
       "Attribute_Before   -0.006891        0.011665          1.000000   \n",
       "Attribute_After    -0.007502        0.012650          1.000000   \n",
       "Delta              -0.009454        0.013810         -0.002284   \n",
       "Type               -0.009810        0.002291         -0.002284   \n",
       "\n",
       "                  Attribute_After     Delta      Type  \n",
       "DocumentID              -0.007502 -0.009454 -0.009810  \n",
       "Attribute_Name           0.012650  0.013810  0.002291  \n",
       "Attribute_Before         1.000000 -0.002284 -0.002284  \n",
       "Attribute_After          1.000000  0.005262  0.002802  \n",
       "Delta                    0.005262  1.000000  0.948129  \n",
       "Type                     0.002802  0.948129  1.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handle_non_numerical_data_correlation(df):\n",
    "    columns = df.columns.values\n",
    "    for column in columns:\n",
    "        text_digit_vals = {}\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "\n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            column_contents = df[column].values.tolist()\n",
    "            unique_elements = set(column_contents)\n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1\n",
    "\n",
    "            df[column] = list(map(convert_to_int, df[column]))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "bc = handle_non_numerical_data_correlation(df_table_cclogattributes)\n",
    "#display(bc)\n",
    "display(bc.corrwith(bc.iloc[0], axis=1))\n",
    "\n",
    "corr = bc.corr(method = 'pearson')\n",
    "corr\n",
    "#plt.figure(figsize=(10,8), dpi =500)\n",
    "#sns.heatmap(corr,annot=True,fmt=\".2f\", linewidth=.5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gruppieren und zählen der eindeutigen Kombinationen\n",
    "# Berechnung der Korrelationswahrscheinlichkeit\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Korrelationsanalyse\n",
    "\n",
    "# Datensatz einlesen\n",
    "df = df_table_cclogattributes\n",
    "\n",
    "df[\"Attribute_Before\"] = pd.to_numeric(df[\"Attribute_Before\"], errors=\"coerce\")\n",
    "df[\"Attribute_After\"] = pd.to_numeric(df[\"Attribute_After\"], errors=\"coerce\")\n",
    "\n",
    "# Entferne Zeilen mit NaN-Werten in den relevanten Spalten\n",
    "df = df.dropna(subset=[\"Attribute_Before\", \"Attribute_After\"])\n",
    "\n",
    "# Korrelationsanalyse durchführen\n",
    "correlation_data = []\n",
    "for attribute_name in df[\"Attribute_Name\"].unique():\n",
    "    attribute_data = df[df[\"Attribute_Name\"] == attribute_name]\n",
    "    if len(attribute_data) > 1:\n",
    "        correlation_coefficient, _ = pearsonr(attribute_data[\"Attribute_Before\"], attribute_data[\"Attribute_After\"])\n",
    "        correlation_data.append({\n",
    "            \"Attribute_Name\": attribute_name,\n",
    "            \"Correlation_Coefficient\": correlation_coefficient\n",
    "        })\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "correlation_df = pd.DataFrame(correlation_data)\n",
    "print(correlation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def cramers_v(confusion_matrix):\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))\n",
    "    rcorr = r - ((r - 1) ** 2) / (n - 1)\n",
    "    kcorr = k - ((k - 1) ** 2) / (n - 1)\n",
    "    return np.sqrt(phi2corr / min((kcorr - 1), (rcorr - 1)))\n",
    "\n",
    "# Korrelationsanalyse mit Cramér's V-Koeffizient\n",
    "correlation_data = []\n",
    "for i in range(len(unique_entries)):\n",
    "    entry_1 = unique_entries[i]\n",
    "    entry_row_1 = df_table_cclogattributes[df_table_cclogattributes[\"Attribute_Name\"] == entry_1]\n",
    "    \n",
    "    for j in range(i+1, len(unique_entries)):\n",
    "        entry_2 = unique_entries[j]\n",
    "        entry_row_2 = df_table_cclogattributes[df_table_cclogattributes[\"Attribute_Name\"] == entry_2]\n",
    "        \n",
    "        if len(entry_row_1) > 0 and len(entry_row_2) > 0:\n",
    "            # Kreuztabelle erstellen\n",
    "            contingency_table = pd.crosstab(entry_row_1[\"Attribute_Before\"], entry_row_2[\"Attribute_Before\"])\n",
    "            \n",
    "            # Cramér's V-Koeffizient berechnen\n",
    "            correlation_coefficient = cramers_v(contingency_table.values)\n",
    "            \n",
    "            correlation_data.append({\n",
    "                \"Attribute_Name_1\": entry_1,\n",
    "                \"Attribute_Name_2\": entry_2,\n",
    "                \"Correlation_Coefficient\": correlation_coefficient\n",
    "            })\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "correlation_df = pd.DataFrame(correlation_data)\n",
    "print(correlation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_attributes = [\"Attribute_Name\", \"Attribute_After\"]\n",
    "target_df = bc[bc[\"Attribute_Name\"].isin(target_attributes)]\n",
    "\n",
    "# Berechnen Sie die Korrelationen der Zielzeilen mit den anderen Zeilen in \"Attribute After\"\n",
    "corr_with_target = target_df[\"Attribute_After\"].corrwith(bc[\"Attribute_After\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/cclogattributes_T0012hb.csv', encoding='iso-8859-15')\n",
    "\n",
    "vergleiche_spalten = lambda x: 'master_data_error' if x['Attribute_Name'] == 'VENDOR_NUM' and x['Attribute_Before'] != x['Attribute_After'] else'good' if x['Delta'] == False and x['Type'] == 0 else 'undefined'\n",
    "#else 'master_data_error' if x['Attribute_Name'] == 'VENDOR_NAME' and x['Attribute_Before'] != x['Attribute_After'] \\\n",
    "#else 'master_data_error' if x['Attribute_Name'] == 'VENDOR_STR' and x['Attribute_Before'] != x['Attribute_After'] \\\n",
    "#else 'master_data_error' if x['Attribute_Name'] == 'VENDOR_CITY' and x['Attribute_Before'] != x['Attribute_After'] \\\n",
    "#else 'master_data_error' if x['Attribute_Name'] == 'VENDOR_ZIP_CODE' and x['Attribute_Before'] != x['Attribute_After'] \\\n",
    "\n",
    "df1['Suggestion'] = df1.apply(vergleiche_spalten, axis=1)\n",
    "\n",
    "df1 = df1.drop('LogTimeTicks', axis=1)\n",
    "#df = df.drop('DocumentID', axis=1)\n",
    "\n",
    "df1.to_csv('data/after_preprocessing.csv', index=False, header= True, encoding='iso-8859-15')\n",
    "\n",
    "X = df1.loc[ : , df1.columns != 'Suggestion']\n",
    "Y = df1.loc[ : , df1.columns == 'Suggestion']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_non_numerical_data(df):\n",
    "    columns = df.columns.values\n",
    "    for column in columns:\n",
    "        text_digit_vals = {}\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "\n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            column_contents = df[column].values.tolist()\n",
    "            unique_elements = set(column_contents)\n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1\n",
    "\n",
    "            df[column] = list(map(convert_to_int, df[column]))\n",
    "\n",
    "    return df\n",
    "\n",
    "#X = handle_non_numerical_data(X)\n",
    "\n",
    "\n",
    "def Encoder(df):\n",
    "          columnsToEncode = list(df.select_dtypes(include=['category','object','bool']))\n",
    "          le = LabelEncoder()\n",
    "          for feature in columnsToEncode:\n",
    "              try:\n",
    "                  df[feature] = le.fit_transform(df[feature])\n",
    "              except:\n",
    "                  print('Error encoding '+feature)\n",
    "          return df\n",
    "\n",
    "\n",
    "#Y = Encoder(Y)\n",
    "#print(Y)\n",
    "#pd.DataFrame(Y).to_csv(\"data/after_numerical.csv\")\n",
    "\n",
    "\n",
    "#print(X)\n",
    "#X.shape[0]\n",
    "#Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and testing samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=None, shuffle=False)\n",
    "\n",
    "pd.DataFrame(y_train).to_csv(\"data/y_train.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam', init='uniform'):\n",
    "    # create model\n",
    "    if verbose: print(\"**Create model with optimizer: %s; init: %s\" % (optimizer, init) )\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=X_train.shape[1], kernel_initializer=init, activation='relu')) #\n",
    "    model.add(Dense(512, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(256, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(3, kernel_initializer=init, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adadelta(), metrics=['acc']) #keras.optimizers.Adadelta() and sparse_categorical_accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_gridsearch = False\n",
    "\n",
    "if run_gridsearch:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    if verbose: print (time.strftime( \"%H:%M:%S \" + \"GridSearch started ... \" ) )\n",
    "    optimizers = ['rmsprop'] # , 'adam'\n",
    "    inits = ['glorot_uniform'] #, 'normal', 'uniform'\n",
    "    epochs = [5, 50, 100, 300]\n",
    "    batches = [5, 32, 64]\n",
    "    \n",
    "    model = KerasClassifier(build_fn=create_model, verbose=verbose)\n",
    "    \n",
    "    param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=inits)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    if verbose: \n",
    "        for mean, stdev, param in zip(means, stds, params):\n",
    "            print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "        elapsed_time = time.time() - start_time  \n",
    "        print (\"Time elapsed: \",timedelta(seconds=elapsed_time))\n",
    "        \n",
    "    best_epochs = grid_result.best_params_['epochs']\n",
    "    best_batch_size = grid_result.best_params_['batch_size']\n",
    "    best_init = grid_result.best_params_['init']\n",
    "    best_optimizer = grid_result.best_params_['optimizer']\n",
    "    \n",
    "else:\n",
    "    # best paramters\n",
    "    best_epochs = 300\n",
    "    best_batch_size = 64\n",
    "    best_init = 'glorot_uniform'\n",
    "    best_optimizer = 'rmsprop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_result.cv_results_)\n",
    "pd.DataFrame(results_df).to_csv('data/grid_search_results.csv')\n",
    "results_df = results_df.sort_values(by=[\"rank_test_score\"])\n",
    "results_df = results_df.set_index(\n",
    "    results_df[\"params\"].apply(lambda x: \"_\".join(str(val) for val in x.values()))\n",
    ").rename_axis(\"kernel\")\n",
    "results_df[[\"params\", \"rank_test_score\", \"mean_test_score\", \"std_test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = results_df.filter(regex=r\"split\\d*_test_score\")\n",
    "\n",
    "# plot 30 examples of dependency between cv fold and AUC scores\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(\n",
    "    data=model_scores.transpose().iloc[:30],\n",
    "    dashes=False,\n",
    "    palette=\"Set1\",\n",
    "    marker=\"o\",\n",
    "    alpha=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(\"CV test fold\", size=12, labelpad=10)\n",
    "ax.set_ylabel(\"Model AUC\", size=12)\n",
    "ax.tick_params(bottom=True, labelbottom=False)\n",
    "ax.legend(loc=4, prop={'size': 6})\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = KerasClassifier(build_fn=create_model, optimizer=best_optimizer, init=best_init, epochs=best_epochs, batch_size=best_batch_size, verbose=verbose)\n",
    "model_pred.fit(X_train, y_train)\n",
    "\n",
    "prediction = model_pred.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, prediction, zero_division=False))\n",
    "accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)\n",
    "pd.DataFrame(prediction).to_csv('data/prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_pred, open('models/classification_model.h5', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/classification_model.h5', 'rb') as pickle_file:\n",
    "    content = pickle.load(pickle_file)\n",
    "\n",
    "prediction = content.predict(X_test)\n",
    "print(classification_report(y_test, prediction, zero_division=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "while True:\n",
    "    for i in range(0,100):\n",
    "        pyautogui.moveTo(10,10)\n",
    "        pyautogui.leftClick()\n",
    "        pyautogui.moveTo(1000,1000)\n",
    "        pyautogui.leftClick()\n",
    "\n",
    "        time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59d736765ce23fba7eae8e4973aae525338b5974b741b35ab5c702ed8c74548c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
